Обнаружение и устранение дубликатов в данных — важный шаг при очистке данных, так как дубликаты могут исказить результаты анализа.

## Методы обнаружения дубликатов:
1. Использование уникальных идентификаторов: 
   Если у записей есть уникальные идентификаторы, можно легко определить дубликаты с помощью поиска одинаковых значений в этом поле.
   
   Пример на Python (pandas):
   ```python
   df[df.duplicated(subset='id')]
   ```
   
2. Сравнение по нескольким полям: 
   Если уникальные идентификаторы отсутствуют, можно искать дубликаты по комбинации нескольких полей (например, имя, фамилия, дата рождения).

   Пример:
   ```python
   df[df.duplicated(subset=['first_name', 'last_name', 'birth_date'])]
   ```
3. Проверка на полные дубликаты строк: 
   Этот метод выявляет строки, которые полностью совпадают по всем полям.

   Пример:
   ```python
   df[df.duplicated()]
   ```
## Методы устранения дубликатов:
1. Удаление всех дубликатов: 
   Простой метод, при котором удаляются все повторяющиеся строки, оставляя одну из них.

   Пример:
   ```python
   df.drop_duplicates()
   ```
2. Сохранение дубликатов с максимальной/минимальной значимостью: 
   В некоторых случаях нужно оставить только дубликат с наибольшим значением в одном из полей.

   Пример:
   ```python
   df.sort_values('timestamp').drop_duplicates(subset=['id'], keep='last')
   ```