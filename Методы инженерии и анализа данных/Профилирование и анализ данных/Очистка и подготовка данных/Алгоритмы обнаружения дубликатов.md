## Группы алгоритмов:
- Простое сравнение строк: Проверка на полные совпадения строк в таблице.
- Методы фингерпринтинга: Использование специальных алгоритмов для поиска частичных дубликатов, например, на основе схожести строк.
- Fuzzy matching (нечёткое сопоставление): Использование алгоритмов вроде Levenshtein Distance для поиска записей, которые могут иметь небольшие различия.

## Метод точного сравнения строк
Подходит для небольших наборов данных с известынми уникальными идентификаторами.
В Pandas библиотеке можно использовать duplicated() для поиска дубликатов.
  ```python  
     import pandas as pd
     df = pd.DataFrame({
         'Name': ['Alice', 'Bob', 'Alice', 'John'],
         'Age': [25, 30, 25, 22]
     })
     duplicates = df[df.duplicated()]
     print(duplicates)
```
### Преимущества:
- Снижение вычислительной сложности при сравнении больших объемов данных.
- Повышение точности при поиске дубликатов, особенно в неструктурированных данных.

### Недостатки:
- Возможные ложные срабатывания при использовании нечётких методов.
- Необходимость предварительной обработки данных для достижения наилучших результатов.


## Методы фингерпринтинга
Используются для выявления дубликатов и схожих записей в наборах данных, особенно когда данные могут содержать ошибки или незначительные различия. Эти методы создают "отпечатки" (фингерпринты) для каждой записи, которые затем сравниваются для выявления совпадений. Вот несколько распространённых методов:

### 1. Метод MinHash
- Описание: Этот метод используется для оценки схожести между множествами, особенно в больших данных. Он создаёт хэш-значения, которые позволяют эффективно сравнивать наборы.
- Применение: Часто используется в задачах поиска похожих документов.

### 2. Locality-Sensitive Hashing (LSH)
- Описание: LSH предназначен для ускорения поиска схожих объектов. Он группирует похожие объекты в одну "корзину", что позволяет сократить количество необходимых сравнений.
- Применение: Эффективен для задач, связанных с изображениями и текстами, где необходимо находить близкие по содержанию записи.

### 3. N-gram фингерпринтинг
- Описание: Этот метод разбивает строки на подстроки фиксированной длины (n-grams), которые затем хэшируются. Сравнение основано на общих подстроках.
- Применение: Полезен для анализа текстов, где важно учитывать порядок символов.

### 4. Soundex и Metaphone
- Описание: Эти алгоритмы преобразуют слова в код, отражающий их произношение. Это позволяет идентифицировать записи, которые звучат похоже, но написаны по-разному.
- Применение: Широко используется в базах данных для обработки имен и фамилий.

### Пример использования N-gram фингерпринтинга:
```python
from sklearn.feature_extraction.text import CountVectorizer

texts = ["apple", "applle", "aapple"]
vectorizer = CountVectorizer(analyzer='char', ngram_range=(2, 2))
X = vectorizer.fit_transform(texts)
print(X.toarray())
```
### Преимущества:
- Высокая точность: Обеспечивает 100% совпадение, что исключает возможность ложных срабатываний.
- Простота реализации: Легко реализовать и понять; обычно требует минимальной обработки данных.
- Быстродействие: Обычно быстрее, особенно на индексированных данных, так как сравнение происходит по точным значениям.

### Недостатки:
- Ограниченная гибкость: Не позволяет выявлять записи с незначительными различиями (опечатки, разные форматы).
- Чувствительность к ошибкам: Легко пропустить записи, если есть малейшее несоответствие (например, пробелы, разные регистры).
- Неэффективность на "грязных" данных: Не может эффективно работать с данными, содержащими много ошибок ввода.


## Методы не точного совпадения (fuzzy matching):

Используются для идентификации дубликатов в данных, когда значения могут не совпадать полностью из-за опечаток, различных форматов записи или других факторов. Рассмотрим несколько популярных методов:

### 1. Метод расстояния Левенштейна  
   Рассчитывает минимальное количество операций (вставка, удаление, замена), необходимых для преобразования одной строки в другую. Чем меньше расстояние Левенштейна между строками, тем они похожи.

   Пример:
     from Levenshtein import distance
   distance("Москва", "Москава")  # вернет 2
   
### 2. Jaccard Similarity  
   Используется для сравнения множеств символов или слов в строках. Рассчитывается как отношение размера пересечения множеств к размеру их объединения.

   Пример:
   ```python
     def jaccard_similarity(str1, str2):
       set1, set2 = set(str1), set(str2)
       return len(set1 & set2) / len(set1 | set2)
       print(jaccard_similarity("Москва", "Москава"))  # вернет 0.833
   ```
### 3. Метод TF-IDF + Косинусное сходство  
   TF-IDF (Term Frequency - Inverse Document Frequency) используется для оценки значимости слов в тексте. После применения TF-IDF сходство между текстами вычисляется с помощью косинусного расстояния, которое измеряет угол между векторами.

   Пример:
   ```python
   from sklearn.feature_extraction.text import TfidfVectorizer
   from sklearn.metrics.pairwise import cosine_similarity
   docs = ["Москва", "Москава"]
   tfidf = TfidfVectorizer().fit_transform(docs)
   print(cosine_similarity(tfidf[0:1], tfidf[1:2]))  # вернет значение близкое к 1
   ```
### Преимущества:
- Обнаружение схожих записей: Позволяет находить дубликаты, даже если они содержат опечатки или незначительные различия (например, "Иванов" и "Иванович").
- Гибкость: Может использоваться для анализа данных с вариативностью в написании или формате.
- Улучшение качества данных: Помогает выявлять неявные дубликаты, что повышает общую точность анализа.

### Недостатки:
- Ложные срабатывания: Может приводить к нахождению записей, которые не являются дубликатами, но звучат или выглядят похоже.
- Сложность реализации: Часто требует более сложных алгоритмов и дополнительной настройки параметров.
- Производительность: Может быть медленнее, чем точное совпадение, особенно на больших объемах данных, из-за необходимости сравнения множества вариантов.