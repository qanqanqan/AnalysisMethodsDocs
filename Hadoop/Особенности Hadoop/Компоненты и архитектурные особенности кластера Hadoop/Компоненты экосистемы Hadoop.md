# Компоненты экосистемы Hadoop

Экосистема Apache Hadoop состоит из множества различных компонентов, которые можно разделить на: 
- основные
- дополнительные

## Основные компоненты
- ***HDFS*** - ***Hadoop Distributed File System*** - распределенная файловая система *Apache Hadoop*, предназначенная для отказоустойчивого и эффективного в плане скорости выполнения операций хранения больших наборов данных. В основе ее используется архитектура с управляющим узлов имен(*NameNode*) и множественными узлами данных(*DataNode*) для управления файлами и метаданными.

- ***YARN*** - ***Yet Another Resource Negotiator*** - система управления ресурсами, управляющая их распределением между множеством приложений в составе кластера *Hadoop*. В ее основу входит менеджер ресурсов(*Resource Manager*) и множество менеджеров узлов(*Node Managers*).

- ***MapReduce*** - модель распределенных вычислений, предназначенная для обработки больших объемов данных(достигающих петабайтов данных) в распределенных системах. В основе технологии лежит принцип последовательного применения операций *Map* и *Reduce*. В общем случае MapReduce работает так: Этап *Map* подразумевает разбиение общего массива данных главным узлом на мелкие подмассивы, их передачу рабочим узлам для дальнейшей обработки. Этап *Reduce* производит свертку обработанных данных - главный узел получает результат от рабочих узлов и формирует окончательный полный результат.

- ***Hadoop Common*** - набор библиотек и утилит, необходимых для поддержки работы прочих модулей *Hadoop*. Является связуючим звеном между различными системами *Hadoop*. Включает в себя библиотеки управления файловыми системами(*HDFS* в том числе), командную оболочку (*FS Shell*), модуль конфигураций(*Common Configuration*), общую инфраструктуру IO операций(*Common IO*) для взаимодействия между файловыми системами, а также модуль безопасности(*Common Security*). 

## Дополнительные компоненты
- ***Hive*** - СУБД с поддержкой SQL-подобных запросов(язык *HQL*) к большим данным, позволяющая управлять, читать и записывать массивы данных, размещенных в хранилище. Преобразует запросы в серию *MapReduce*-задач. Используется для обработки больших массивов данных и их подготовке к анализу или визуализации, а также к выгрузке в реляционные базы данных.

- ***Pig*** - платформа для обработки и анализа больших данных в составе *Hadoop*. Включает в себя процедурный язык для описания потоков *Pig Latin* и исполнительную среду для запусков сценариев *Pig Latin*(запуск сценариев доступен на локальной *JVM* или в среде *Hadoop*).

- ***Spark*** - платформа для обработки больших данных, предлагающая расширенные возможности в сравнении со стандартным *MapReduce* подходом - фактически имеет механизм, являющийся его логическим продолжением. *Apache Spark* значительно быстрее *MapReduce*, поскольку использует метод обработки данных в памяти(*in-memory processing*), что позволяет избежать затрат времени на чтение и запись данных на диск и делает *Spark* более эффективным инструментом для аналитических задач и обработки потоковых данных. Может работать как в составе кластера *Hadoop*, так и во внешней среде. *Spark* имеет ряд высокоуровневых API, позволяющих вести разработку на языках Java, Scala, Python, R.

- ***HBase*** - распределенная NoSQL СУБД, предназначенная для хранения и обработки больших объемов данных, обеспечивая произвольный доступ к данным в режиме реального времени. Используется аналогичная *BigTable* модель хранения данных, работающая на основе *HDFS*. *HBase* использует столбцовую модель хранения данных, то есть данные в ней представлены в виде таблиц, которая может эффективно хранить миллиарды строк и миллионы столбцов. В составе *Hadoop* используется для хранения больших объемов логов, реализации систем аналитики в реальном времени, в обработке временных рядов, а также для поддержки приложений с быстрым доступом к данным.

- ***Oozie*** - система планирования рабочих процессов для управления заданиями в *Hadoop*. Она позволяет пользователям управлять(и создавать) сложными потоками обработки данных, которые могут включать в себя различные задачи: *MapReduce*-этап, скрипты и программы *Hive*, *Spark*, *Pig* и так далее. Все рабочие процессы, рассматриваемые в *Oozie*, представляются в виде ориентированного ациклического графа. Позволяет автоматизировать ETL-процессы, управлять сложными аналитическими потоками данных, планировать регулярное выполнение заданий, а также налаживать координацию действий между процессами.

- ***Sqoop*** - инструмент передачи данных между реляционными БД и *Hadoop*. Позволяет эффективно испортировать массивы данных из SQL СУБД(PostgreSQL, MySQL, Oracle и прочих) в *HDFS*, а так же экспортировать данные обратно. *Sqoop* использует архитектуру на основе коннекторов, позволяющих ей взаимодействовать с различными СУБД. На текущий момент компонент является неактивным, так что в новых проектах желательно использование альтернативных инструментов вместо него, например *Kafka*, *Spark* или *Flume*.

- ***Flume*** - распределенная система агрегации, сбора и передачи больших массивов данных, логов и событий в системе *Hadoop*. *Flume* обеспечивает надежную и масштабируемую архитектуру для передачи данных в *HDFS*, а благодаря поддержке широкого спектра испочников, способен брать и записывать данные из различных БД, систем обмена сообщениями(*Kafka*) и пользовательских источников(посредством API). *Flume* использует событийную модель, в которой данные собираются в группу события, что позволяет эффективно обрабатывать и передавать данные в режиме реального времени.

- ***ZooKeeper*** - сервис-координатор, обеспечивающий распределенную синхронизацию метаданных и прочих небольших данных, включающих в себя конфигурационную информацию, пространство имен, состояние и местонахождение узлов системы. Также выступает в роли избирателя главного узла среди прочих. Хранение информации организовано в формате "ключ-значение" в оперативной памяти, что делает использование инструмента достаточно быстрым.

Каждый из компонентов выполняет свою четко отведенную работу внутри большой экосистемы Hadoop.