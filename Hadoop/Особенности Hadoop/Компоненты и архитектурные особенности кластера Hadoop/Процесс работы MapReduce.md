# Процесс работы MapReduce

## Программная модель map/reduce
Выполнение распределенных задач на платформе Hadoop происходит в рамках парадигмы *map/reduce*.

*map/reduce* – это парадигма (программная модель) выполнения распределенных вычислений для больших объемов данных.
В общем случае, для map/reduce выделяют 2 фазы:
- map(ƒ, c)
Принимает функцию ƒ и список c. Возвращает выходной список, являющийся результатом применения функции ƒ к каждому элементу входного списка c.

<div style='text-align: center'>
<img src='https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgVYl9-DY2bvLFx-9BL1l6x5zoDDgST0csSRZ7Ef3g-cmk_F1IqnkyJrraPwjfOKNKVOh-cJoDhXVBOk7xUEjVsjIrjalWtjdhvRuPvx0uMzISejewtGVKrRKL6qnT6ddyObXEPi2hpKOU-/s1600/map.PNG'>
</div>

- reduce(ƒ, c)
Принимает функцию ƒ и список c. Возвращает объект, образованный через свертку коллекции c через функцию ƒ.

<div style='text-align: center'>
<img src='https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEixCSOQ4slr0x5aF6p4MItypBcX2-Lt5Q1SODiWOumZTVr5_tLxwmmOYpNlq6eEKffix8UkIIVrWNNoujL2ztkCjUUbdUHZHx53MZuXsPYMv68jdTOBXpbhyphenhyphen20K-SdI7kKTrqm0ZM8aSqzY/s1600/reduce.PNG'>
</div>

Программная модель map/reduce была позаимствована из функционального программирования, хотя в реализации Hadoop и имеет некоторые семантические отличия от прототипа в функциональных языках.

## Процесс работы MapReduce

Работу Hadoop MapReduce можно условно поделить на следующие этапы:
___
- ### <u>Input read</u>

Входные данные делятся на блоки данных предопределенного размера (от 16 Мб до 256 Мб) – сплиты (от англ. split). MapReduce Framework закрепляет за каждой функцией Map определенный сплит.
___
- ### <u>Map</u>

Каждая функция Map получает на вход список пар «ключ/значение» (k,v), обрабатывает их и на выходе получает ноль или более пар (k',v'), являющихся промежуточным результатом.

```map(k, v) -> [(k', v')]```

где k' - в общем случае, произвольный ключ, не совпадающий с k.
Все операции map() выполняются параллельно и не зависят от результатов работы друг друга. Каждая функция map() получает на вход свой уникальный набор данных, не повторяющийся ни для какой другой функции map().
___
- ### <u>Partition / Combine</u>

Целью этапа partition (разделение) является распределение промежуточных результатов, полученных на этапе map, по reduce-заданиям.

```(k', reducers_count) -> reducer_id``` 

где reducers_count - количество узлов, на которых запускается операция свертки;
reducer_id - идентификатор целевого узла.
В простейшем случае,

```reducer_id = hash(k') mod reducers_count```

Основная цель этапа partition – это балансировка нагрузки. Некорректно реализованная функция partition может привести к неравномерному распределению данных между reduce-узлами.
Функция combine запускается после map-фазы. В ней происходит промежуточная свертка, локальных по отношению к функции map, значений.

```[(k', v')] -> (k', [v'])```

Основное значение функции combine – комбинирование промежуточных данных, что в свою очередь ведет, к уменьшению объема передаваемой между узлами информации.

<div style='text-align: center'>
<img src='https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEggzmcagm7QU1i5N6xDgi6yD9VGLX1jiyDY4TIqt0nNRIGNr9fK83bp-IwQtDM724QIVzYetoy5oAYP4fZErKMKMO5Ti6RGMQcTuV76lardg7j1zsu5wB7KVedgWxcbPocWPyUJ75cRPJVh/s1600/combine.PNG'>
</div>

___
- ### <u>Copy / Сompare / Merge</u>

На этом этапе происходит:

- Copy

Копирование результатов, полученных в результате работы функций map и combine (если такая была определена), с map-узлов на reduce-узлы.

- Сompare (или Sort)

Cортировка, группировка по ключу k полученных в результате операции copy промежуточных значений на reduce-узле.

```compare(k'n, k'n+1) -> {-1, 0, +1}```

- Merge

«слияние» данных, полученных от разных узлов, для операции свёртки.

___

- ### <u>Reduce</u>

Framework вызывает функцию reduce для каждого уникального ключа k' в отсортированном списке значений.

```reduce(k', [v']) -> [v'']```

Все операции reduce() выполняются параллельно и не зависят от результатов работы друг друга. Таким образом, результаты работы каждой функции reduce() пишутся в отдельный выходной поток.

___

- ### <u>Output write</u>

Результаты, полученные на этапе reduce, записываются в выходной поток (в общем случае, файловые блоки в HDFS). Каждый reduce-узел пишет в собственный выходной поток.
<div style='text-align: center'>
<img src='https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjKhdpcyXk6oY2PK4_kKJpFJt7pamjWZk2gljABiHMWV9cconjx9V4lvkDuzZhTXM4C6z8sY2xdh7ifuK8wyRH7jlfSwtL6lSVgOSb0fBYtp5ykquZ7rQS0UyxcXCG9lNyPi4SQtQ-U-Unc/s1600/a.PNG'>
</div>

Разработчику приложения для Hadoop MapReduce необходимо реализовать базовый обработчик, который на каждом вычислительном узле кластера обеспечит преобразование исходных пар «ключ/значение» в промежуточный набор пар «ключ/значение» (класс, реализующий интерфейс Mapper), и обработчик, сводящий промежуточный набор пар в окончательный, сокращённый набор (класс, реализующий интерфейс Reducer).
Все остальные фазы выполняются программной моделью MapReduce без дополнительного кодирования со стороны разработчика. Кроме того, среда выполнения Hadoop MapReduce выполняет следующие функции:
- планирование заданий;
- распараллеливание заданий;
- перенос заданий к данным;
- синхронизация выполнения заданий;
- перехват «проваленных» заданий;
- обработка отказов выполнения заданий и перезапуск проваленных заданий;
- оптимизация сетевых взаимодействий.