## Как происходит распределение данных в HDFS?

В HDFS (Hadoop Distributed File System) распределение данных осуществляется с целью обеспечения высокой доступности, надежности и производительности при работе с большими объёмами данных. Процесс распределения данных в HDFS включает несколько ключевых этапов:

### 1. Разделение файлов на блоки
- Размер блоков: При загрузке файла в HDFS он разбивается на фиксированные блоки. По умолчанию размер блока составляет 128 МБ (в более старых версиях — 64 МБ), но этот параметр можно настроить в конфигурации. Меньшие файлы могут занимать меньше одного блока, в то время как большие файлы распределяются по нескольким блокам.

### 2. Репликация блоков
- Копии блоков: Каждый блок файла дублируется на нескольких узлах в кластере для повышения надежности и доступности данных. По умолчанию HDFS создаёт три копии каждого блока (репликация по умолчанию равна 3), хотя это значение может быть изменено для отдельных файлов или для всей системы. Репликация защищает данные от потери в случае сбоя узла.

### 3. Выбор узлов для хранения блоков
- Глобальный планировщик: Когда HDFS распределяет блоки, он использует алгоритмы для выбора узлов, на которых будут храниться реплики. HDFS стремится хранить реплики блоков на разных узлах, а также убирать реплики с одного и того же rack (стойки с серверами) для повышения устойчивости к сбоям.

### 4. Хранение блоков в DataNode
- DataNode: Блоки хранятся на узлах, называемых DataNode. Каждый DataNode отвечает за хранение, чтение и запись блоков, а также за выполнение операций над данными. DataNode регулярно отправляет отчеты о состоянии (heartbeats) в NameNode, чтобы информировать о своем состоянии и доступных ресурсах.

### 5. Управление метаданными
- NameNode: HDFS использует централизованный узел, называемый NameNode, который хранит метаданные о блоках и их местоположении. NameNode следит за тем, какие блоки принадлежат каким файлам, где хранятся реплики и каково состояние узлов в кластере.

### 6. Запись и чтение данных
- Потоковая запись: При записи данных в HDFS пользователь отправляет файл на NameNode, который разбивает его на блоки и определяет узлы для хранения. Блоки отправляются к DataNode в несколько этапов: сначала записывается первый узел, затем передаётся на следующий, и так до тех пор, пока не будут созданы все реплики блока.

- Потоковое чтение: При запросе файла NameNode возвращает информацию о расположении блоков и их реплик, что позволяет клиентским приложениям обращаться к DataNode для считывания данных. Данные считываются и передаются по сети, обеспечивая высокую производительность.