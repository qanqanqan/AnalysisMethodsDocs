# Балансировка и восстановление данных в случае сбоя DataNode в HDFS

Hadoop Distributed File System (HDFS) обеспечивает хранение больших объемов данных, распределяя их на множестве узлов (DataNode). Для обеспечения надежности система создает несколько копий (реплик) каждого блока данных на разных узлах. В случае сбоя DataNode, HDFS автоматически восстанавливает данные и реплики для минимизации потерь и обеспечения отказоустойчивости. Этот документ описывает процесс балансировки данных в кластере и восстановление данных в случае сбоя DataNode.

## 1. Балансировка данных в HDFS

### 1.1. Неравномерное распределение данных

В процессе работы кластера данные могут быть распределены неравномерно среди узлов DataNode. Это может произойти из-за добавления новых узлов в кластер или выполнения операций записи/чтения, которые создают диспропорции в использовании дискового пространства. Неравномерное распределение данных может привести к снижению производительности и эффективного использования ресурсов.

### 1.2. Инструмент балансировки HDFS

HDFS предоставляет специальный инструмент для балансировки данных между узлами — **Balancer**. Этот инструмент перемещает блоки данных с перегруженных узлов DataNode на менее загруженные, сохраняя при этом целостность и доступность данных.

#### 1.2.1. Как работает балансировщик

- **Анализ загруженности**: Балансировщик сканирует состояние всех узлов DataNode и вычисляет средний уровень использования хранилища.
- **Перемещение блоков**: Узлы с уровнем использования, превышающим среднее значение, передают некоторые блоки данных на узлы с более низким уровнем загруженности. Эти операции выполняются в фоновом режиме без прерывания работы кластера.
  
#### 1.2.2. Параметры настройки балансировщика

- **Threshold** (порог) — это основной параметр балансировщика, который определяет допустимое отклонение уровня использования дисков от среднего значения по кластеру. Например, при значении порога в 10%, узлы с использованием дисков на 10% выше или ниже среднего значения будут участвовать в балансировке.
  
Балансировка может занять длительное время в зависимости от объема данных и числа узлов в кластере, но она важна для поддержания равномерного распределения нагрузки и оптимальной производительности кластера.

### 1.3. Запуск балансировщика

Балансировщик HDFS может быть запущен вручную командой:

```bash
hdfs balancer -threshold <value>
```
- Где <value> — значение порога, например 10.

Также возможно автоматизировать процесс балансировки, настроив регулярные запуски балансировщика с помощью планировщиков задач, таких как cron.

## 2. Восстановление данных в случае сбоя DataNode
### 2.1. Что происходит при сбое DataNode
DataNode могут выйти из строя по разным причинам, таким как сбои аппаратного обеспечения, переполнение диска или сетевые проблемы. Когда NameNode перестает получать 'сердцебиение' от узла DataNode (по умолчанию через 10 минут), этот узел считается "мертвым". В этот момент HDFS выполняет следующие действия:

Помечает блоки как недоступные: Все блоки данных, хранящиеся на вышедшем из строя узле, помечаются как недоступные.
Планирует восстановление реплик: Если фактор репликации нарушен (то есть осталось меньше реплик, чем задано конфигурацией), NameNode начинает процесс восстановления недостающих реплик на других узлах DataNode.
### 2.2. Восстановление реплик
После сбоя DataNode NameNode инициирует процесс создания недостающих реплик блоков данных на других доступных узлах:

- Выбор узлов для репликации: NameNode выбирает DataNode с достаточным количеством свободного дискового пространства для размещения новых копий блоков данных.
- Передача блоков: Недостающие блоки данных копируются с доступных узлов на новые DataNode, чтобы восстановить исходный фактор репликации.
- Актуализация метаданных: После успешного завершения репликации NameNode обновляет свои метаданные, фиксируя новые расположения блоков.
### 2.3. Минимизация времени простоя
HDFS спроектирован так, чтобы минимизировать время простоя при сбоях DataNode. Репликация блоков данных происходит в фоновом режиме, и пользователи могут продолжать работать с кластером, если хотя бы одна реплика блока остается доступной.

### 2.4. Восстановление после повторного подключения DataNode
Если DataNode снова становится доступным после сбоя, он начинает передавать 'сердцебиения' на NameNode, и его блоки данных могут быть вновь использованы. Если за время отсутствия узла были созданы новые реплики блоков, избыточные копии данных на восстановленном DataNode могут быть автоматически удалены, чтобы не превышать заданный фактор репликации.

### 2.5. Балансировка после восстановления
После восстановления узла или завершения процесса репликации балансировщик данных (Balancer) может быть использован для оптимального распределения данных в кластере, чтобы обеспечить равномерное использование дискового пространства и улучшить производительность.

## 3. Профилактика сбоев DataNode
### 3.1. Мониторинг состояния DataNode
Для минимизации рисков сбоев DataNode в HDFS можно настроить мониторинг ключевых параметров, таких как:

- Состояние дисков (свободное/занятое пространство, состояние здоровья).
- Использование оперативной памяти и процессора.
- Сетевые соединения и пропускная способность.
### 3.2. Предотвращение переполнения дисков
Переполнение дисков является одной из частых причин сбоев DataNode. Важно настраивать автоматическое оповещение при достижении критических уровней заполнения дисков и проводить регулярные операции по балансировке данных.

### 3.3. Настройка Rack Awareness
Использование Rack Awareness (осведомленность о стойках) помогает улучшить отказоустойчивость, так как HDFS размещает реплики данных на узлах в разных стойках. Это позволяет снизить риск одновременного сбоя нескольких реплик данных в случае сбоя всей стойки.

## 4. Заключение
Балансировка данных и восстановление после сбоев DataNode являются важными аспектами обеспечения надежности и производительности HDFS. Инструменты HDFS, такие как Balancer и механизм автоматической репликации, позволяют поддерживать равномерное распределение данных и обеспечивают оперативное восстановление системы в случае сбоев. Мониторинг состояния узлов, правильная настройка Rack Awareness и регулярное использование балансировщика данных помогают минимизировать риск сбоев и обеспечивают бесперебойную работу распределенной файловой системы.