## Просмотр статистики использования дискового пространства в HDFS

В Hadoop Distributed File System (HDFS) есть несколько команд и инструментов для просмотра статистики использования дискового пространства. Это важно для администраторов кластера, чтобы следить за занятостью хранилища и управлять ресурсами. Рассмотрим, как можно получить такую информацию.

### 1. Использование команды `hadoop dfs -du`

Команда `hadoop dfs -du` позволяет увидеть использование дискового пространства для файлов и каталогов в HDFS. Пример:

```bash
hadoop dfs -du -h /путь/к/каталогу/
```

- Опция `-h` позволяет выводить размеры в человеко-читаемом формате (например, KB, MB, GB).

### 2. Использование команды `hadoop dfs -count`

Команда `hadoop dfs -count` предоставляет статистику по количеству файлов и объемам. Пример:

```bash
hadoop dfs -count /путь/к/каталогу/
```

Вывод команды будет включать количество файлов, количество каталогов и общее дисковое пространство, которое занимает каталог и его содержимое.

### 3. Использование `hadoop fsck`

Команда `hadoop fsck` предоставляет общую информацию о состоянии HDFS, включая использование дискового пространства. Например:

```bash
hadoop fsck /
```

Этот запрос вернет состояние всей файловой системы, включая количество файлов и пространственные данные.

### 4. Получение общей информации о файловой системе

Вы можете получить обзор использования дискового пространства на уровне всей файловой системы, выполнив:

```bash
hdfs dfsadmin -report
```

Эта команда вернет информацию о статусе HDFS, включая:

- Общее хранилище
- Используемое хранилище
- Доступное хранилище
- Общая информация о дата-узлах кластера

### 5. Использование Web UI для HDFS

Также можно использовать веб-интерфейс Hadoop (обычно доступен по умолчанию на порту 50070 или 9870, в зависимости от версии) для просмотра статистики. Здесь вы сможете увидеть:

- Хранилище по дата-узлам
- Использование диска для всех файлов в HDFS
- Статистику, связанную с конкретными файлами и каталогами

### Примечания

- Обязательно проверьте наличие необходимых прав доступа перед выполнением команд.
- Источники займут различные объемы дискового пространства в зависимости от конфигурации вашего кластера и версии Hadoop.