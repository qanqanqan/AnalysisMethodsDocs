Управление дисковым пространством в HDFS — это важный аспект администрирования Hadoop-кластера, который включает в себя такие задачи, как эффективное использование дисков, предотвращение их переполнения, мониторинг и контроль использования пространства, а также обеспечение отказоустойчивости данных. В этом процессе задействованы различные механизмы и инструменты HDFS, которые помогают администраторам контролировать использование хранилища и управлять доступными ресурсами.

Вот основные аспекты управления дисковым пространством в HDFS:

# 1. Архитектура хранения данных в HDFS
В HDFS данные хранятся в виде блоков фиксированного размера (обычно 128 МБ или 256 МБ). Каждый файл разбивается на такие блоки и реплицируется на нескольких узлах DataNode. Эффективное управление дисковым пространством начинается с понимания того, как HDFS управляет файлами и блоками:

- Размер блоков: Как уже упоминалось, увеличение размера блоков может снизить нагрузку на NameNode, но при этом важно помнить, что слишком большие блоки могут замедлить доступ к мелким файлам.
- Репликация: Каждый блок имеет несколько копий (реплик), по умолчанию три. Это обеспечивает отказоустойчивость, но увеличивает потребление дискового пространства. Снижение числа реплик для менее критичных данных может уменьшить нагрузку на диски.
# 2. Квоты на использование дискового пространства
HDFS предоставляет возможность установки квот на дисковое пространство для пользователей, групп и директорий. Это позволяет администраторам ограничивать использование пространства, предотвращая его исчерпание одним пользователем или задачей.

## Квота на количество файлов и директорий:

- Квота на количество файлов и директорий может быть установлена для предотвращения создания слишком большого числа мелких файлов, которые перегружают NameNode.
- Пример команды для установки квоты на количество файлов:
```bash
hdfs dfsadmin -setQuota 100000 /user/myuser
```
## Квота на использование дискового пространства:

- Можно ограничить объем дискового пространства, который может использовать конкретная директория.
- Пример команды для установки квоты на пространство:
```bash
hdfs dfsadmin -setSpaceQuota 500g /user/myuser
```

## Удаление квоты:

- Если квота больше не требуется, ее можно снять:
```bash
hdfs dfsadmin -clrQuota /user/myuser
hdfs dfsadmin -clrSpaceQuota /user/myuser
```
# 3. Удаление неиспользуемых и временных файлов
Со временем в HDFS могут скапливаться временные файлы, лог-файлы или неиспользуемые данные, которые занимают дисковое пространство. Важно регулярно удалять такие данные для освобождения ресурсов:

## Команда fsck для поиска поврежденных или "потерянных" файлов:

- Команда hdfs fsck может помочь найти поврежденные файлы или файлы без реплик, которые можно удалить:
```arduino
hdfs fsck / -delete
```
## Удаление старых файлов с помощью политики жизненного цикла данных:

- Автоматизированное удаление устаревших данных можно настроить через такие инструменты, как Apache Falcon или политики хранения данных на основе времени (time-based retention policies).
# 4. Балансировка дискового пространства
HDFS может со временем неравномерно распределять данные между узлами DataNode. Одни узлы могут оказаться перегружены, а другие — недоиспользованы. Для выравнивания нагрузки между узлами используется встроенный механизм балансировки.

## Запуск балансировщика:

- Команда для запуска балансировки:
```bash
hdfs balancer -threshold 10
```

Здесь -threshold 10 указывает, что балансировщик будет стараться минимизировать разницу в использовании пространства на DataNode до 10%.

## Настройка пропускной способности балансировщика:

- Вы можете ограничить скорость работы балансировщика, чтобы избежать избыточной нагрузки на сеть:
```xml
<property>
  <name>dfs.datanode.balance.bandwidthPerSec</name>
  <value>10485760</value> <!-- 10 MB/sec -->
</property>
```
# 5. Репликация данных и управление пространством
Репликация — один из основных механизмов HDFS, который обеспечивает отказоустойчивость, но также увеличивает использование дискового пространства. Эффективное управление репликацией может помочь сократить избыточное потребление ресурсов.

## Изменение числа реплик:

- Можно вручную изменить количество реплик для файлов, чтобы снизить нагрузку на диски:
```bash
hdfs dfs -setrep -w 2 /user/myfile
```

## Контроль недостающих реплик:

- Команда hdfs fsck может быть использована для поиска файлов с недостающими репликами, чтобы обеспечить их восстановление и избежать потерь данных:
```bash
hdfs fsck / -blocks -locations -racks
```
6. Механизм "гербиджа" (Trash) в HDFS
Когда файлы удаляются из HDFS, они не удаляются сразу. Система перемещает их в специальную директорию Trash, откуда их можно восстановить в течение определенного времени, прежде чем они будут окончательно удалены. Это помогает предотвратить случайное удаление важных данных, но также может увеличить использование дискового пространства.

## Настройка времени хранения в Trash:

- Время хранения данных в Trash можно настроить с помощью параметра fs.trash.interval в файле core-site.xml:
```xml
<property>
  <name>fs.trash.interval</name>
  <value>360</value> <!-- Время в минутах, например, 6 часов -->
</property>
```
## Ручное удаление данных из Trash:

- Если нужно немедленно освободить место, можно очистить Trash вручную:
```bash
hdfs dfs -expunge
```
# Заключение
Эффективное управление дисковым пространством в HDFS требует регулярного мониторинга, настройки квот, балансировки нагрузки и удаления неиспользуемых данных. Использование таких механизмов, как квоты, балансировщики, политики хранения и аудит, позволяет администраторам поддерживать производительность кластера и предотвращать проблемы с исчерпанием ресурсов.