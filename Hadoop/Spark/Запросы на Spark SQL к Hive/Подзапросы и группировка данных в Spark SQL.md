# Подзапросы и группировка данных в Spark SQL

В Spark SQL, подзапросы и группировка данных являются важными инструментами для обработки и анализа данных.

    Подзапросы:
    Подзапросы в Spark SQL позволяют вам вложить один запрос внутри другого, что дает возможность выполнять более сложные вычисления и фильтрацию данных.

## Пример подзапроса:

### Создание тестовых данных

```py
df = spark.createDataFrame([
    (1, "Alice", 25),
    (2, "Bob", 30),
    (3, "Charlie", 35),
    (4, "David", 40)
], ["id", "name", "age"])
```
### Подзапрос, чтобы найти средний возраст
```py
avg_age = df.select(avg("age")).collect()[0][0]
```
### Основной запрос, который использует подзапрос

```py
result_df = df.where(df.age > avg_age)
result_df.show()
```
Группировка данных:
Группировка данных в Spark SQL позволяет вам разделить ваши данные на группы, основываясь на одном или нескольких столбцах, и применять агрегационные функции к этим группам.

Пример группировки данных:

### Создание тестовых данных
```py
df = spark.createDataFrame([
    (1, "A", 10),
    (2, "A", 20),
    (3, "B", 30),
    (4, "B", 40)
], ["id", "group", "value"])
```
## Группировка данных по столбцу "group" и применение агрегационной функции "sum"
```py
grouped_df = df.groupBy("group").agg(
    sum("value").alias("total_value")
)
grouped_df.show()
```
Результат:
```
+-----+------------+
|group|total_value|
+-----+------------+
|    A|         30|
|    B|         70|
+-----+------------+
```
В этом примере мы сгруппировали данные по столбцу "group" и применили агрегационную функцию "sum" к столбцу "value", чтобы получить общую сумму значений для каждой группы.

Подзапросы и группировка данных являются мощными инструментами в Spark SQL, которые позволяют вам выполнять сложные вычисления и анализировать данные на более глубоком уровне.