## RDD (Resilient Distributed Datasets): основы и операции

RDD (Resilient Distributed Dataset) — это основная абстракция данных в Apache Spark, представляющая собой неизменяемую, распределённую коллекцию объектов, которая позволяет работать с большими данными параллельно и отказоустойчиво. Вот основные аспекты и операции, связанные с RDD:

### Основы RDD:

1. **Неизменяемость**: RDD неизменяемы, что означает, что они не могут быть изменены после создания. Вместо этого, при выполнении операций над RDD создаются новые RDD.

2. **Распределённость**: Данные в RDD распределены по кластерам, что позволяет обрабатывать их параллельно.

3. **Отказоустойчивость**: RDD автоматически восстанавливаются после сбоев, используя механизм lineage (происхождение данных), который отслеживает операции, применённые к данным.

4. **Ленивая оценка**: Операции над RDD выполняются лениво, что означает, что они не выполняются до тех пор, пока не потребуется результат. Это позволяет Spark оптимизировать выполнение.

5. **Кэширование**: RDD могут быть кэшированы в памяти, что ускоряет повторное использование данных.

### Основные операции с RDD:

Операции с RDD делятся на два типа: трансформации и действия.

#### Трансформации:

Трансформации создают новые RDD из существующих. Они ленивы и не выполняются сразу.

- **map(func)**: Применяет функцию `func` к каждому элементу RDD и возвращает новый RDD с результатами.
  
- **filter(func)**: Создаёт новый RDD, содержащий только элементы, для которых функция `func` возвращает `true`.

- **flatMap(func)**: Похожа на `map()`, но позволяет каждому элементу входного RDD соответствовать ноль или более элементов в выходном RDD.

- **groupByKey()**: Группирует данные по ключу. Эффективна для (K, V) пар, но может быть дорогостоящей из-за перераспределения данных.

- **reduceByKey(func)**: Сокращает пары ключ-значение по ключу, применяя функцию `func`. Часто более эффективна, чем `groupByKey()`.

- **union(otherRDD)**: Объединяет два RDD, возвращая новый RDD, содержащий элементы обоих.

- **distinct()**: Возвращает новый RDD, содержащий только уникальные элементы.

#### Действия:

Действия вычисляют и возвращают результат на драйвер или сохраняют его во внешнее хранилище. Они запускают выполнение трансформаций.

- **collect()**: Возвращает все элементы RDD в виде массива на драйвере. Используется с осторожностью для больших наборов данных.

- **count()**: Возвращает количество элементов в RDD.

- **take(n)**: Возвращает первые `n` элементов RDD.

- **reduce(func)**: Применяет функцию `func`, которая принимает два аргумента и возвращает одно значение, чтобы свести RDD к одному значению.

- **foreach(func)**: Применяет функцию `func` к каждому элементу RDD. Обычно используется для побочных эффектов, таких как запись в базу данных.

RDD предоставляют гибкость и контроль для работы с большими данными, но требуют более низкоуровневого программирования по сравнению с DataFrame и Dataset.