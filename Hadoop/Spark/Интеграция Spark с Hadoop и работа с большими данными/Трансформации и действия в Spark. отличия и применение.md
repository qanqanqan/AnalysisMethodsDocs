В Spark существуют два основных типа операций: трансформации и действия.

 1. Трансформации (Transformations):
Трансформации являются ленивыми операциями. Это означает, что они не выполняются сразу после вызова, а лишь создают новый RDD (или DataFrame), который будет вычислен, когда будет вызвано действие. Примеры трансформаций:
 • map()
 • filter()
 • flatMap()
 • groupBy()
 • reduceByKey()
Трансформации создают новый набор данных на основе существующего, но данные не вычисляются до тех пор, пока не будет вызвано действие.
Пример трансформации в PySpark:
```python
rdd = sc.parallelize([1, 2, 3, 4, 5])
rdd_transformed = rdd.map(lambda x: x * 2)  # Трансформация
```

 2. Действия (Actions):
Действия запускают выполнение всех предыдущих трансформаций и возвращают результат. Они являются триггером для вычислений в Spark. Примеры действий:
 • collect()
 • count()
 • reduce()
 • saveAsTextFile()
 • take()
Когда вызывается действие, Spark начинает вычислять все цепочки трансформаций, чтобы получить результат.
Пример действия в PySpark:
```python
result = rdd_transformed.collect()  # Действие, которое запускает вычисления
print(result)
```


Таким образом, трансформации определяют, как данные будут обрабатываться, а действия фактически запускают выполнение и возвращают результат.